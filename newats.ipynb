{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjAy1F1RH36z",
        "outputId": "f3db72db-638f-4cf7-f74b-d83b3c39b2a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: click in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from nltk) (1.4.2)\n",
            "Collecting regex>=2021.8.3 (from nltk)\n",
            "  Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
            "Collecting tqdm (from nltk)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from click->nltk) (0.4.6)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.5/1.5 MB 9.7 MB/s eta 0:00:00\n",
            "Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl (273 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: tqdm, regex, nltk\n",
            "Successfully installed nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting lxml>=3.1.0 (from python-docx)\n",
            "  Downloading lxml-5.3.0-cp313-cp313-win_amd64.whl.metadata (3.9 kB)\n",
            "Collecting typing-extensions>=4.9.0 (from python-docx)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "Downloading lxml-5.3.0-cp313-cp313-win_amd64.whl (3.8 MB)\n",
            "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
            "   ------------------------ --------------- 2.4/3.8 MB 12.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 3.8/3.8 MB 11.4 MB/s eta 0:00:00\n",
            "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: typing-extensions, lxml, python-docx\n",
            "Successfully installed lxml-5.3.0 python-docx-1.1.2 typing-extensions-4.12.2\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: Pillow in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (11.0.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py): started\n",
            "  Building wheel for fpdf (setup.py): finished with status 'done'\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40713 sha256=d5f5564b45c7b937371fb7de2541425829f9bdcf60e654bbecfccd59dd0404eb\n",
            "  Stored in directory: c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local\\pip\\cache\\wheels\\aa\\da\\11\\a3189f34ddc13c26a2d0f329eac46b728c7f31c39e4dc26243\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: plotly in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from plotly) (24.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "!pip install python-docx\n",
        "!pip install Pillow\n",
        "!pip install fpdf\n",
        "!pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl0BlkV0U4Wa",
        "outputId": "f53b7854-5170-4bba-cf6e-df2f2833d111"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting altair<6,>=4.0 (from streamlit)\n",
            "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (1.9.0)\n",
            "Collecting cachetools<6,>=4.0 (from streamlit)\n",
            "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: click<9,>=7.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (2.2.0)\n",
            "Requirement already satisfied: packaging<25,>=20 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (2.2.3)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (11.0.0)\n",
            "Collecting protobuf<6,>=3.20 (from streamlit)\n",
            "  Downloading protobuf-5.29.2-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
            "Collecting pyarrow>=7.0 (from streamlit)\n",
            "  Downloading pyarrow-18.1.0-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (2.32.3)\n",
            "Collecting rich<14,>=10.14.0 (from streamlit)\n",
            "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (9.0.0)\n",
            "Collecting toml<2,>=0.10.1 (from streamlit)\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit)\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
            "  Downloading narwhals-1.18.4-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
            "  Downloading attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
            "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
            "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
            "  Downloading rpds_py-0.22.3-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
            "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
            "   --------- ------------------------------ 2.1/9.1 MB 13.8 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 6.0/9.1 MB 16.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 9.1/9.1 MB 17.5 MB/s eta 0:00:00\n",
            "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
            "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
            "   --------------------------------------- 731.2/731.2 kB 22.0 MB/s eta 0:00:00\n",
            "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "Downloading protobuf-5.29.2-cp310-abi3-win_amd64.whl (434 kB)\n",
            "Downloading pyarrow-18.1.0-cp313-cp313-win_amd64.whl (25.1 MB)\n",
            "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
            "   -------- ------------------------------- 5.2/25.1 MB 27.5 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 10.7/25.1 MB 26.0 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 17.6/25.1 MB 28.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  24.9/25.1 MB 30.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 25.1/25.1 MB 26.4 MB/s eta 0:00:00\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
            "   ---------------------------------------  6.8/6.9 MB 33.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 6.9/6.9 MB 30.4 MB/s eta 0:00:00\n",
            "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Downloading narwhals-1.18.4-py3-none-any.whl (251 kB)\n",
            "Downloading attrs-24.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
            "Downloading rpds_py-0.22.3-cp313-cp313-win_amd64.whl (235 kB)\n",
            "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: watchdog, toml, smmap, rpds-py, pyarrow, protobuf, narwhals, mdurl, cachetools, attrs, referencing, pydeck, markdown-it-py, gitdb, rich, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
            "Successfully installed altair-5.5.0 attrs-24.3.0 cachetools-5.5.0 gitdb-4.0.11 gitpython-3.1.43 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 markdown-it-py-3.0.0 mdurl-0.1.2 narwhals-1.18.4 protobuf-5.29.2 pyarrow-18.1.0 pydeck-0.9.1 referencing-0.35.1 rich-13.9.4 rpds-py-0.22.3 smmap-5.0.1 streamlit-1.41.1 toml-0.10.2 watchdog-6.0.0\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting PyPDF2==3.0.1\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting google.generativeai\n",
            "  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting google-ai-generativelanguage==0.6.10 (from google.generativeai)\n",
            "  Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting google-api-core (from google.generativeai)\n",
            "  Downloading google_api_core-2.24.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting google-api-python-client (from google.generativeai)\n",
            "  Downloading google_api_python_client-2.156.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting google-auth>=2.15.0 (from google.generativeai)\n",
            "  Downloading google_auth-2.37.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: protobuf in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from google.generativeai) (5.29.2)\n",
            "Collecting pydantic (from google.generativeai)\n",
            "  Downloading pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: tqdm in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from google.generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from google.generativeai) (4.12.2)\n",
            "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.10->google.generativeai)\n",
            "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google.generativeai)\n",
            "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from google-api-core->google.generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from google-auth>=2.15.0->google.generativeai) (5.5.0)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google.generativeai)\n",
            "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google.generativeai)\n",
            "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google.generativeai)\n",
            "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google.generativeai)\n",
            "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google.generativeai)\n",
            "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic->google.generativeai)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic->google.generativeai)\n",
            "  Downloading pydantic_core-2.27.2-cp313-cp313-win_amd64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from tqdm->google.generativeai) (0.4.6)\n",
            "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google.generativeai)\n",
            "  Downloading grpcio-1.68.1-cp313-cp313-win_amd64.whl.metadata (4.0 kB)\n",
            "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google.generativeai)\n",
            "  Downloading grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google.generativeai) (3.2.0)\n",
            "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google.generativeai)\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2024.12.14)\n",
            "Downloading google_generativeai-0.8.3-py3-none-any.whl (160 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl (760 kB)\n",
            "   ---------------------------------------- 0.0/760.0 kB ? eta -:--:--\n",
            "   --------------------------- ------------ 524.3/760.0 kB 4.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 760.0/760.0 kB 3.1 MB/s eta 0:00:00\n",
            "Downloading google_api_core-2.24.0-py3-none-any.whl (158 kB)\n",
            "Downloading google_auth-2.37.0-py2.py3-none-any.whl (209 kB)\n",
            "Downloading google_api_python_client-2.156.0-py2.py3-none-any.whl (12.7 MB)\n",
            "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
            "   --- ------------------------------------ 1.0/12.7 MB 5.3 MB/s eta 0:00:03\n",
            "   -------- ------------------------------- 2.6/12.7 MB 6.6 MB/s eta 0:00:02\n",
            "   ------------- -------------------------- 4.5/12.7 MB 7.6 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 7.6/12.7 MB 9.5 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 11.3/12.7 MB 11.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 12.7/12.7 MB 11.5 MB/s eta 0:00:00\n",
            "Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
            "Downloading pydantic_core-2.27.2-cp313-cp313-win_amd64.whl (2.0 MB)\n",
            "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.0/2.0 MB 20.7 MB/s eta 0:00:00\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
            "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "Downloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
            "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
            "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Downloading grpcio-1.68.1-cp313-cp313-win_amd64.whl (4.4 MB)\n",
            "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
            "   -------------------------------------- - 4.2/4.4 MB 23.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 4.4/4.4 MB 19.8 MB/s eta 0:00:00\n",
            "Downloading grpcio_status-1.68.1-py3-none-any.whl (14 kB)\n",
            "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Installing collected packages: uritemplate, pydantic-core, pyasn1, proto-plus, httplib2, grpcio, googleapis-common-protos, annotated-types, rsa, pydantic, pyasn1-modules, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google.generativeai\n",
            "Successfully installed annotated-types-0.7.0 google-ai-generativelanguage-0.6.10 google-api-core-2.24.0 google-api-python-client-2.156.0 google-auth-2.37.0 google-auth-httplib2-0.2.0 google.generativeai-0.8.3 googleapis-common-protos-1.66.0 grpcio-1.68.1 grpcio-status-1.68.1 httplib2-0.22.0 proto-plus-1.25.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pydantic-2.10.4 pydantic-core-2.27.2 rsa-4.9 uritemplate-4.1.1\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting streamlit_extras\n",
            "  Downloading streamlit_extras-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting entrypoints>=0.4 (from streamlit_extras)\n",
            "  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting htbuilder>=0.6.2 (from streamlit_extras)\n",
            "  Downloading htbuilder-0.7.0.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting markdownlit>=0.0.5 (from streamlit_extras)\n",
            "  Downloading markdownlit-0.0.7-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: plotly>=1.0.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit_extras) (5.24.1)\n",
            "Collecting prometheus-client>=0.14.0 (from streamlit_extras)\n",
            "  Downloading prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: protobuf!=3.20.2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit_extras) (5.29.2)\n",
            "Collecting st-annotated-text>=3.0.0 (from streamlit_extras)\n",
            "  Downloading st_annotated_text-4.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting st-theme>=1.0.1 (from streamlit_extras)\n",
            "  Downloading st_theme-1.2.3-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: streamlit>=1.0.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit_extras) (1.41.1)\n",
            "Collecting streamlit-camera-input-live>=0.2.0 (from streamlit_extras)\n",
            "  Downloading streamlit_camera_input_live-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting streamlit-card>=0.0.4 (from streamlit_extras)\n",
            "  Downloading streamlit_card-1.0.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting streamlit-embedcode>=0.1.2 (from streamlit_extras)\n",
            "  Downloading streamlit_embedcode-0.1.2-py3-none-any.whl.metadata (414 bytes)\n",
            "Collecting streamlit-faker>=0.0.2 (from streamlit_extras)\n",
            "  Downloading streamlit_faker-0.0.3-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting streamlit-image-coordinates<0.2.0,>=0.1.1 (from streamlit_extras)\n",
            "  Downloading streamlit_image_coordinates-0.1.9-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting streamlit-keyup>=0.1.9 (from streamlit_extras)\n",
            "  Downloading streamlit_keyup-0.2.4-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting streamlit-toggle-switch>=1.0.2 (from streamlit_extras)\n",
            "  Downloading streamlit_toggle_switch-1.0.2-py3-none-any.whl.metadata (395 bytes)\n",
            "Collecting streamlit-vertical-slider>=2.5.5 (from streamlit_extras)\n",
            "  Downloading streamlit_vertical_slider-2.5.5-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting validators>=0.20.0 (from streamlit_extras)\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting more-itertools (from htbuilder>=0.6.2->streamlit_extras)\n",
            "  Downloading more_itertools-10.5.0-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting markdown (from markdownlit>=0.0.5->streamlit_extras)\n",
            "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: lxml in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from markdownlit>=0.0.5->streamlit_extras) (5.3.0)\n",
            "Collecting favicon (from markdownlit>=0.0.5->streamlit_extras)\n",
            "  Downloading favicon-0.7.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting pymdown-extensions (from markdownlit>=0.0.5->streamlit_extras)\n",
            "  Downloading pymdown_extensions-10.12-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from plotly>=1.0.0->streamlit_extras) (9.0.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from plotly>=1.0.0->streamlit_extras) (24.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=1.0.0->streamlit_extras) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=1.0.0->streamlit_extras) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=1.0.0->streamlit_extras) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=1.0.0->streamlit_extras) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=1.0.0->streamlit_extras) (2.2.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=1.0.0->streamlit_extras) (2.2.3)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=1.0.0->streamlit_extras) (11.0.0)\n",
            "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=1.0.0->streamlit_extras) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=1.0.0->streamlit_extras) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=1.0.0->streamlit_extras) (13.9.4)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=1.0.0->streamlit_extras) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=1.0.0->streamlit_extras) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=1.0.0->streamlit_extras) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=1.0.0->streamlit_extras) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=1.0.0->streamlit_extras) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit>=1.0.0->streamlit_extras) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit-camera-input-live>=0.2.0->streamlit_extras) (3.1.4)\n",
            "Collecting faker (from streamlit-faker>=0.0.2->streamlit_extras)\n",
            "  Downloading Faker-33.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from streamlit-faker>=0.0.2->streamlit_extras) (3.10.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from altair<6,>=4.0->streamlit>=1.0.0->streamlit_extras) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from altair<6,>=4.0->streamlit>=1.0.0->streamlit_extras) (1.18.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from click<9,>=7.0->streamlit>=1.0.0->streamlit_extras) (0.4.6)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.0.0->streamlit_extras) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit>=1.0.0->streamlit_extras) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit>=1.0.0->streamlit_extras) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit>=1.0.0->streamlit_extras) (2024.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jinja2->streamlit-camera-input-live>=0.2.0->streamlit_extras) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.27->streamlit>=1.0.0->streamlit_extras) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.27->streamlit>=1.0.0->streamlit_extras) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.27->streamlit>=1.0.0->streamlit_extras) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.27->streamlit>=1.0.0->streamlit_extras) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from rich<14,>=10.14.0->streamlit>=1.0.0->streamlit_extras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from rich<14,>=10.14.0->streamlit>=1.0.0->streamlit_extras) (2.18.0)\n",
            "Collecting beautifulsoup4>=4.7.0 (from favicon->markdownlit>=0.0.5->streamlit_extras)\n",
            "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit_extras) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit_extras) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit_extras) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit_extras) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit_extras) (3.2.0)\n",
            "Collecting pyyaml (from pymdown-extensions->markdownlit>=0.0.5->streamlit_extras)\n",
            "  Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4>=4.7.0->favicon->markdownlit>=0.0.5->streamlit_extras)\n",
            "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.0.0->streamlit_extras) (5.0.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.0.0->streamlit_extras) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.0.0->streamlit_extras) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.0.0->streamlit_extras) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.0.0->streamlit_extras) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=1.0.0->streamlit_extras) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit>=1.0.0->streamlit_extras) (1.17.0)\n",
            "Downloading streamlit_extras-0.5.0-py3-none-any.whl (77 kB)\n",
            "Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
            "Downloading markdownlit-0.0.7-py3-none-any.whl (15 kB)\n",
            "Downloading prometheus_client-0.21.1-py3-none-any.whl (54 kB)\n",
            "Downloading st_annotated_text-4.0.1-py3-none-any.whl (9.0 kB)\n",
            "Downloading st_theme-1.2.3-py3-none-any.whl (75 kB)\n",
            "Downloading streamlit_camera_input_live-0.2.0-py3-none-any.whl (6.6 kB)\n",
            "Downloading streamlit_card-1.0.2-py3-none-any.whl (680 kB)\n",
            "   ---------------------------------------- 0.0/680.8 kB ? eta -:--:--\n",
            "   ---------------------------------------- 680.8/680.8 kB 6.5 MB/s eta 0:00:00\n",
            "Downloading streamlit_embedcode-0.1.2-py3-none-any.whl (3.5 kB)\n",
            "Downloading streamlit_faker-0.0.3-py3-none-any.whl (14 kB)\n",
            "Downloading streamlit_image_coordinates-0.1.9-py3-none-any.whl (7.0 kB)\n",
            "Downloading streamlit_keyup-0.2.4-py3-none-any.whl (7.4 kB)\n",
            "Downloading streamlit_toggle_switch-1.0.2-py3-none-any.whl (635 kB)\n",
            "   ---------------------------------------- 0.0/635.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 635.4/635.4 kB 7.8 MB/s eta 0:00:00\n",
            "Downloading streamlit_vertical_slider-2.5.5-py3-none-any.whl (1.8 MB)\n",
            "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.8/1.8 MB 22.3 MB/s eta 0:00:00\n",
            "Downloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "Downloading Faker-33.1.0-py3-none-any.whl (1.9 MB)\n",
            "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.9/1.9 MB 29.1 MB/s eta 0:00:00\n",
            "Downloading favicon-0.7.0-py2.py3-none-any.whl (5.9 kB)\n",
            "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "Downloading more_itertools-10.5.0-py3-none-any.whl (60 kB)\n",
            "Downloading pymdown_extensions-10.12-py3-none-any.whl (263 kB)\n",
            "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
            "Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
            "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
            "Building wheels for collected packages: htbuilder\n",
            "  Building wheel for htbuilder (setup.py): started\n",
            "  Building wheel for htbuilder (setup.py): finished with status 'done'\n",
            "  Created wheel for htbuilder: filename=htbuilder-0.7.0-py3-none-any.whl size=12502 sha256=b577813f9cd844fa5c423ecc5ac2a33af1a538a86daccfd33e85d9db3f7397ed\n",
            "  Stored in directory: c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local\\pip\\cache\\wheels\\4b\\0f\\0e\\fe73579ecc8ce225ba77e873ab4cad69e9bdb6df8961c4a12b\n",
            "Successfully built htbuilder\n",
            "Installing collected packages: validators, soupsieve, pyyaml, prometheus-client, more-itertools, markdown, entrypoints, pymdown-extensions, htbuilder, faker, beautifulsoup4, st-annotated-text, favicon, streamlit-vertical-slider, streamlit-toggle-switch, streamlit-keyup, streamlit-image-coordinates, streamlit-embedcode, streamlit-card, streamlit-camera-input-live, st-theme, streamlit-faker, markdownlit, streamlit_extras\n",
            "Successfully installed beautifulsoup4-4.12.3 entrypoints-0.4 faker-33.1.0 favicon-0.7.0 htbuilder-0.7.0 markdown-3.7 markdownlit-0.0.7 more-itertools-10.5.0 prometheus-client-0.21.1 pymdown-extensions-10.12 pyyaml-6.0.2 soupsieve-2.6 st-annotated-text-4.0.1 st-theme-1.2.3 streamlit-camera-input-live-0.2.0 streamlit-card-1.0.2 streamlit-embedcode-0.1.2 streamlit-faker-0.0.3 streamlit-image-coordinates-0.1.9 streamlit-keyup-0.2.4 streamlit-toggle-switch-1.0.2 streamlit-vertical-slider-2.5.5 streamlit_extras-0.5.0 validators-0.34.0\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pdf2image) (11.0.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: nltk in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (3.9.1)\n",
            "Requirement already satisfied: click in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from click->nltk) (0.4.6)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: python-docx in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from python-docx) (4.12.2)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting fpdf2\n",
            "  Downloading fpdf2-2.8.2-py2.py3-none-any.whl.metadata (67 kB)\n",
            "Collecting defusedxml (from fpdf2)\n",
            "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: Pillow!=9.2.*,>=6.2.2 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from fpdf2) (11.0.0)\n",
            "Requirement already satisfied: fonttools>=4.34.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from fpdf2) (4.55.3)\n",
            "Downloading fpdf2-2.8.2-py2.py3-none-any.whl (236 kB)\n",
            "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: defusedxml, fpdf2\n",
            "Successfully installed defusedxml-0.7.1 fpdf2-2.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n",
        "!pip install PyPDF2==3.0.1\n",
        "!pip install google.generativeai\n",
        "!pip install python-dotenv\n",
        "!pip install streamlit_extras\n",
        "!pip install pdf2image\n",
        "!pip install nltk\n",
        "!pip install python-docx\n",
        "!pip install fpdf2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrmtAk97VIiQ",
        "outputId": "fe9e5c6e-6239-4ce4-d74e-38d1fd460f10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'apt-get' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGJPAf_hwDUD",
        "outputId": "1bcc0907-391e-4ffb-a16e-939dc9bf6464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import PyPDF2\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from docx import Document\n",
        "import difflib  # For calculating similarity in plagiarism check\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "import base64\n",
        "import os\n",
        "from PIL import Image\n",
        "import pdf2image\n",
        "import google.generativeai as genai\n",
        "from io import BytesIO\n",
        "from fpdf import FPDF\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Set Streamlit page config at the top\n",
        "st.set_page_config(page_title=\"GLA ATS System\", page_icon=\":guardsman:\")\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Configure Google Generative AI\n",
        "genai.configure(api_key=(\"AIzaSyACVj30Yv9r03qxBz-b7oKUf_JUHMHbKTw\"))\n",
        "\n",
        "def get_gemini_response(resume_text, job_desc_text, prompt):\n",
        "    \"\"\"Fetches a response from Gemini API.\"\"\"\n",
        "    try:\n",
        "        model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "        # Combine inputs into a single text blob\n",
        "        input_text = f\"Resume:\\n{resume_text}\\n\\nJob Description:\\n{job_desc_text}\\n\\nPrompt:\\n{prompt}\"\n",
        "\n",
        "        response = model.generate_content(input_text)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error in Gemini API: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    reader = PyPDF2.PdfReader(pdf_file)\n",
        "    text = ''\n",
        "    for page_num in range(len(reader.pages)):\n",
        "        page = reader.pages[page_num]\n",
        "        text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def input_pdf_setup(pdf_file):\n",
        "    return [extract_text_from_pdf(pdf_file)]\n",
        "\n",
        "# Define the PDF class\n",
        "class PDF(FPDF):\n",
        "    def add_section(self, title, content):\n",
        "        # Add section title\n",
        "        self.set_font('Arial', 'B', 14)\n",
        "        self.cell(200, 10, title, ln=True)\n",
        "        self.set_font('Arial', '', 12)\n",
        "        self.multi_cell(0, 10, content)\n",
        "        self.ln(5)  # Add some space after each section\n",
        "\n",
        "def generate_resume():\n",
        "# Function to generate PDF\n",
        "    def generate_pdf(name, email, phone, skills, education, work_experience, projects, achievements, certifications, hobbies):\n",
        "        from io import BytesIO\n",
        "        from reportlab.lib.pagesizes import letter\n",
        "        from reportlab.pdfgen import canvas\n",
        "\n",
        "        buffer = BytesIO()\n",
        "        c = canvas.Canvas(buffer, pagesize=letter)\n",
        "        text = c.beginText(50, 750)\n",
        "\n",
        "        # Add content to the PDF\n",
        "        text.setFont(\"Helvetica\", 12)\n",
        "        text.textLine(f\"Name: {name}\")\n",
        "        text.textLine(f\"Email: {email}\")\n",
        "        text.textLine(f\"Phone: {phone}\")\n",
        "        text.textLine(\"Skills:\")\n",
        "        text.textLines(skills)\n",
        "        text.textLine(\"Education:\")\n",
        "        text.textLines(education)\n",
        "        text.textLine(\"Work Experience:\")\n",
        "        text.textLines(work_experience)\n",
        "        text.textLine(\"Projects:\")\n",
        "        text.textLines(projects)\n",
        "        text.textLine(\"Achievements:\")\n",
        "        text.textLines(achievements)\n",
        "        text.textLine(\"Certifications:\")\n",
        "        text.textLines(certifications)\n",
        "        text.textLine(\"Hobbies:\")\n",
        "        text.textLines(hobbies)\n",
        "\n",
        "        c.drawText(text)\n",
        "        c.save()\n",
        "\n",
        "        buffer.seek(0)\n",
        "        return buffer\n",
        "\n",
        "    # User inputs\n",
        "    name = st.text_input(\"Name\")\n",
        "    email = st.text_input(\"Email\")\n",
        "    phone = st.text_input(\"Phone Number\")\n",
        "    skills = st.text_area(\"Skills\")\n",
        "    education = st.text_area(\"Education\")\n",
        "    work_experience = st.text_area(\"Work Experience\")\n",
        "    projects = st.text_area(\"Projects\")\n",
        "    achievements = st.text_area(\"Achievements\")\n",
        "    certifications = st.text_area(\"Certifications\")\n",
        "    hobbies = st.text_area(\"Hobbies\")\n",
        "\n",
        "    # Generate Resume\n",
        "    if st.button(\"Generate Resume\"):\n",
        "        # Check if all fields are filled\n",
        "        if not all([name, email, phone, skills, education, work_experience, projects, achievements, certifications, hobbies]):\n",
        "            st.warning(\"Please fill in all fields before generating the resume.\")\n",
        "        else:\n",
        "            # Generate the PDF\n",
        "            pdf = generate_pdf(\n",
        "                name,\n",
        "                email,\n",
        "                phone,\n",
        "                skills,\n",
        "                education,\n",
        "                work_experience,\n",
        "                projects,\n",
        "                achievements,\n",
        "                certifications,\n",
        "                hobbies,\n",
        "            )\n",
        "\n",
        "            # Provide download link\n",
        "            st.download_button(\n",
        "                label=\"Download PDF\",\n",
        "                data=pdf,\n",
        "                file_name=\"resume.pdf\",\n",
        "                mime=\"application/pdf\"\n",
        "            )\n",
        "\n",
        "def calculate_similarity(text1, text2):\n",
        "    \"\"\"\n",
        "    Calculate similarity percentage between two texts using difflib.\n",
        "    \"\"\"\n",
        "    text1 = text1.lower().strip()  # Normalize text\n",
        "    text2 = text2.lower().strip()  # Normalize text\n",
        "\n",
        "    similarity = difflib.SequenceMatcher(None, text1, text2).ratio()\n",
        "    return round(similarity * 100, 2)\n",
        "\n",
        "def get_plagiarism_percentage(resume_text, job_desc_text):\n",
        "    \"\"\"\n",
        "    Get plagiarism percentage using Gemini API with optimized prompt.\n",
        "    \"\"\"\n",
        "    prompt = \"\"\"\n",
        "    You are a skilled plagiarism detection system with expertise in text analysis. Your task is to compare the provided resume text and job description text.\n",
        "    Evaluate the degree of similarity between these texts and calculate a plagiarism percentage, considering semantic and lexical similarities.\n",
        "    Exclude general phrases or commonly used terms in resumes and job descriptions.\n",
        "    Provide the result as a numerical percentage value only (e.g., 85).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = get_gemini_response(resume_text, job_desc_text, prompt)\n",
        "        # Ensure response is a valid numerical percentage\n",
        "        plagiarism_percentage = int(response) if response.isdigit() else None\n",
        "        return plagiarism_percentage\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error calculating plagiarism: {e}\")\n",
        "        return None\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"**GLA University ATS System**\")\n",
        "st.subheader(\"About\")\n",
        "st.write(\"This sophisticated ATS project, developed with Gemini Pro and Streamlit, seamlessly incorporates advanced features including resume match percentage, keyword analysis to identify missing criteria, and the generation of comprehensive profile summaries, enhancing the efficiency and precision of the candidate evaluation process for discerning talent acquisition professionals.\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "  - [Streamlit](https://streamlit.io/)\n",
        "  - [Gemini Pro](https://deepmind.google/technologies/gemini/#introduction)\n",
        "  - [makersuit API Key](https://makersuite.google.com/)\n",
        "\"\"\")\n",
        "\n",
        "# Sidebar for input\n",
        "st.sidebar.header(\"Upload Your Job Description\")\n",
        "job_desc_file = st.sidebar.file_uploader(\"Upload Job Description (PDF)\", type=\"pdf\")\n",
        "\n",
        "\n",
        "#Prompts\n",
        "input_prompt1 = \"\"\"\n",
        " You are an experienced Technical Human Resource Manager. Your task is to review the provided resume against the job description.\n",
        "Please share your professional evaluation on whether the candidate's profile aligns with the role. Highlight the strengths and weaknesses\n",
        "of the applicant in relation to the specified job requirements.\n",
        "\"\"\"\n",
        "\n",
        "input_prompt3 = \"\"\"\n",
        "You are a skilled ATS (Applicant Tracking System) scanner with a deep understanding of ATS functionality.\n",
        "Your task is to evaluate the resume_pdf_content against the provided pdf_content and provide a match percentage.\n",
        "The output should be a numerical percentage value only, without any additional text or symbols (e.g., 75).\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "input_prompt4 = \"\"\"\n",
        "You are an skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality,\n",
        "your task is to evaluate the resume against the provided job description. give me the relevant skills if the resume matches\n",
        "the job description. The output should come as text containing all relevant skills required for given job description .\n",
        "\"\"\"\n",
        "\n",
        "input_prompt5 = \"\"\"\n",
        "You are an skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality,\n",
        "your task is to evaluate the resume against the provided job description. give me the non-relevant skills if the resume matches\n",
        "the job description. The output should come as text containing all non-relevant skills mentioned in resume that are not required for given job description .\n",
        "\"\"\"\n",
        "\n",
        "input_prompt7 = \"\"\"\n",
        "You are a skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality.\n",
        "Your task is to evaluate the resume against the provided job description and return only the Relevant Projects, for the given job description.\n",
        "The output should come as text containing all relevant projects required for given job description.\n",
        "\"\"\"\n",
        "\n",
        "input_prompt8 = \"\"\"\n",
        "You are a skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality.\n",
        "Your task is to evaluate the resume against the provided job description and return only the Recommended Skills required that are not available in resume but given in job description.\n",
        "The output should come as text containing all recommended skills required for given job description.\n",
        "\"\"\"\n",
        "\n",
        "# If a job description is uploaded\n",
        "if job_desc_file is not None:\n",
        "    op = st.sidebar.selectbox(\"Resume:\", [\"Choose an option\", \"Yes, I have\", \"No, I have to create.\"])\n",
        "    pdf_content = input_pdf_setup(job_desc_file)\n",
        "    job_desc_text = pdf_content[0]\n",
        "\n",
        "    # Call the API with the prompts\n",
        "    if op == \"Yes, I have\":\n",
        "        st.subheader(\"Your Resume\")\n",
        "        resume_file = st.file_uploader(\"Upload Your Resume (PDF)\", type=\"pdf\")\n",
        "\n",
        "        if resume_file is not None:\n",
        "            opt = st.sidebar.selectbox(\"Available Options\", [\"Choose an option\",\"Percentage match\", \"Show Relevant Skills\", \"Non-relevant Skills\", \"Plagiarism Score\", \"Relevant Projects\", \"Recommended Skills\", \"Tell Me About the Resume\"])\n",
        "            resume_pdf_content = input_pdf_setup(resume_file)\n",
        "            resume_text = resume_pdf_content[0]\n",
        "\n",
        "            # Get match percentage\n",
        "            if opt == \"Percentage match\":\n",
        "              response = get_gemini_response(input_prompt3, resume_pdf_content, job_desc_text[0])\n",
        "              # Display the percentage as a progress bar\n",
        "              st.subheader(\"Percentage Match\")\n",
        "              st.progress(int(response))\n",
        "              st.write(f\"Match: {response}%\")\n",
        "\n",
        "            # Get relevant skills\n",
        "            if opt == \"Show Relevant Skills\":\n",
        "              relevant_skills = get_gemini_response(resume_text, pdf_content, input_prompt4)\n",
        "              st.write(\"Relevant Skills:\")\n",
        "              st.write(relevant_skills)\n",
        "\n",
        "            # Get non-relevant skills\n",
        "            if opt == \"Non-relevant Skills\":\n",
        "              non_relevant_skills = get_gemini_response(resume_text, pdf_content, input_prompt5)\n",
        "              st.write(\"Non-Relevant Skills:\")\n",
        "              st.write(non_relevant_skills)\n",
        "\n",
        "            # Get plagiarism percentage\n",
        "            if opt == \"Plagiarism Score\":\n",
        "                st.subheader(\"Plagiarism Score\")\n",
        "\n",
        "                # Preprocess texts\n",
        "                resume_clean = resume_text.lower().strip()\n",
        "                job_desc_clean = job_desc_text.lower().strip()\n",
        "\n",
        "                # Local similarity calculation\n",
        "                plagiarism_score = calculate_similarity(resume_clean, job_desc_clean)\n",
        "                st.write(\"Plagiarism Score (Local Calculation):\")\n",
        "                st.progress(int(plagiarism_score))\n",
        "                st.write(f\"{plagiarism_score}%\")\n",
        "\n",
        "                # Gemini API similarity check\n",
        "                st.write(\"Plagiarism Score (Gemini API Calculation):\")\n",
        "                gemini_score = get_plagiarism_percentage(resume_clean, job_desc_clean)\n",
        "                if gemini_score is not None:\n",
        "                    st.progress(int(gemini_score))\n",
        "                    st.write(f\"{gemini_score}%\")\n",
        "                else:\n",
        "                    st.write(\"Unable to retrieve Gemini API plagiarism score.\")\n",
        "\n",
        "            # Get relevant projects\n",
        "            if opt == \"Relevant Projects\":\n",
        "              relevant_projects = get_gemini_response(resume_text, pdf_content, input_prompt7)\n",
        "              st.write(\"Relevant Projects:\")\n",
        "              st.write(relevant_projects)\n",
        "\n",
        "            # Get recommended skills\n",
        "            if opt == \"Recommended Skills\":\n",
        "              recommended_skills = get_gemini_response(resume_text, pdf_content, input_prompt8)\n",
        "              st.write(\"Recommended Skills:\")\n",
        "              st.write(recommended_skills)\n",
        "\n",
        "            if opt == \"Tell Me About the Resume\":\n",
        "              st.subheader(\"Detailed Evaluation of Resume\")\n",
        "              evaluation_response = get_gemini_response(resume_pdf_content, pdf_content, input_prompt1)\n",
        "              if evaluation_response:\n",
        "                  st.write(evaluation_response)\n",
        "\n",
        "    if op == \"No, I have to create.\":\n",
        "        generate_resume()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "8COXk3O1VXlk",
        "outputId": "5585f80d-f06e-4130-d886-df37fbb6c68b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n%%writefile app.py\\nimport streamlit as st\\nimport PyPDF2\\nimport nltk\\nfrom collections import Counter\\nfrom docx import Document\\nimport difflib  # For calculating similarity in plagiarism check\\nfrom dotenv import load_dotenv\\nload_dotenv()\\nimport base64\\nimport os\\nfrom PIL import Image\\nimport pdf2image\\nimport google.generativeai as genai\\nfrom io import BytesIO\\nfrom fpdf import FPDF\\n\\nnltk.download(\\'punkt\\')\\nnltk.download(\\'stopwords\\')\\nfrom nltk.corpus import stopwords\\nfrom nltk.tokenize import word_tokenize\\n\\n\\n# Configure Google Generative AI\\ngenai.configure(api_key=(\"AIzaSyAHrZuX0mzeKQUTtUNX1zv3dNO-m56T_nU\"))\\n\\n\\ndef get_gemini_response(input, pdf_content, prompt):\\n    model = genai.GenerativeModel(\\'gemini-1.5-flash\\')\\n    response = model.generate_content([input, pdf_content[0], prompt])\\n    return response.text\\n\\ndef get_gemini_response1(input_prompt):\\n    model = genai.GenerativeModel(\\'gemini-1.5-flash\\')\\n    response = model.generate_content(input_prompt)\\n    return response.text\\n\\ndef extract_text_from_pdf(pdf_file):\\n    reader = PyPDF2.PdfReader(pdf_file)\\n    text = \\'\\'\\n    for page_num in range(len(reader.pages)):\\n        page = reader.pages[page_num]\\n        text += page.extract_text()\\n    return text\\n\\n\\ndef input_pdf_setup(pdf_file):\\n    return [extract_text_from_pdf(pdf_file)]\\n\\ndef extract_skills(text):\\n    skill_set = {\\'python\\', \\'java\\', \\'data analysis\\', \\'project management\\', \\'machine learning\\', \\'communication\\', \\'sql\\'}\\n    tokens = word_tokenize(text.lower())\\n    cleaned_tokens = [word for word in tokens if word.isalpha() and word not in stopwords.words(\\'english\\')]\\n    relevant_skills = skill_set.intersection(cleaned_tokens)\\n    return relevant_skills\\n\\ndef generate_pdf(content):\\n    # Function to generate a PDF from the given resume content\\n    pdf = FPDF()\\n    pdf.add_page()\\n    pdf.set_font(\"Arial\", size=12)\\n\\n    # Split content into lines and add each line to the PDF\\n    for line in content.split(\"\\n\"):\\n        pdf.cell(200, 10, txt=line, ln=True)\\n\\n    # Save the PDF to a BytesIO object\\n    pdf_output = BytesIO()\\n    pdf.output(pdf_output)\\n    pdf_output.seek(0)\\n\\n    return pdf_output\\n\\ndef generate_pdf(content):\\n    # Function to generate a PDF from the given resume content\\n    pdf = FPDF()\\n    pdf.add_page()\\n    pdf.set_font(\"Arial\", size=12)\\n\\n    # Replace unsupported Unicode characters\\n    content = content.replace(\"–\", \"-\")  # Replace en-dash with a hyphen\\n    content = content.replace(\"—\", \"--\")  # Replace em-dash with double hyphen\\n    content = content.replace(\"•\", \"*\")  # Replace bullet points with asterisks\\n\\n    # Split content into lines and add each line to the PDF\\n    for line in content.split(\"\\n\"):\\n        try:\\n            pdf.cell(200, 10, txt=line.encode(\\'latin-1\\', \\'replace\\').decode(\\'latin-1\\'), ln=True)\\n        except UnicodeEncodeError as e:\\n            st.error(f\"Error encoding line: {line} - {e}\")\\n\\n    # Save the PDF to a BytesIO object\\n    pdf_output = BytesIO()\\n    pdf.output(pdf_output)\\n    pdf_output.seek(0)\\n\\n    return pdf_output\\n\\ndef generate_resume():\\n    st.header(\"Create Your Resume\")\\n\\n    # Taking inputs from the user\\n    name = st.text_input(\"Enter Name\")\\n    email = st.text_input(\"Enter Email\")\\n    phone = st.text_input(\"Enter Phone Number\")\\n    skills = st.text_area(\"Enter Skills\")\\n    education = st.text_area(\"Enter Education\")\\n    work_experience = st.text_area(\"Enter Work Experience\")\\n    projects = st.text_area(\"Enter Projects\")\\n    achievements = st.text_area(\"Enter Achievements\")\\n    certifications = st.text_area(\"Enter Certifications\")\\n    hobbies = st.text_area(\"Enter Hobbies\")\\n\\n    # Once all inputs are received\\n    if st.button(\"Generate Resume\"):\\n        # Prepare the input prompt for AI generation\\n        input_prompt9 = f\"\"\"\\n        You are a skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality.\\n        Your task is to create the resume for the provided job description and return the resume that was created by using the user inputs:\\n        Name: {name}\\n        Email: {email}\\n        Phone Number: {phone}\\n\\n        Skills: {skills}\\n\\n        Education: {education}\\n\\n        Work Experience: {work_experience}\\n\\n        Projects: {projects}\\n\\n        Achievements: {achievements}\\n\\n        Certifications: {certifications}\\n\\n        Hobbies: {hobbies}\\n        The output should come as a PDF file containing the generated resume.\\n        \"\"\"\\n\\n        # Get the response from the AI model\\n        response = get_gemini_response1(input_prompt9)\\n\\n        # Display the generated resume to the user\\n        st.subheader(\"Generated Resume\")\\n        st.write(response)\\n\\n        # Generate a PDF from the response\\n        pdf = generate_pdf(response)\\n\\n        # Provide a download button for the generated PDF\\n        st.download_button(\\n            label=\"Download Resume as PDF\",\\n            data=pdf,\\n            file_name=f\"{name}_resume.pdf\",\\n            mime=\"application/pdf\"\\n        )\\n\\n\\n\\n\\ndef tailor_resume(resume_text, job_desc_text):\\n    # Extract skills from the job description\\n    jd_skills = extract_skills(job_desc_text)\\n\\n    # Tokenize and clean the resume text\\n    resume_tokens = word_tokenize(resume_text.lower())\\n    resume_cleaned_tokens = [word for word in resume_tokens if word.isalpha() and word not in stopwords.words(\\'english\\')]\\n\\n    # Identify relevant and missing skills\\n    relevant_resume_skills = set(resume_cleaned_tokens).intersection(jd_skills)\\n    missing_skills = jd_skills - relevant_resume_skills\\n\\n    # Load resume into a docx template for editing\\n    doc = Document()\\n    doc.add_heading(\\'Tailored Resume\\', 0)\\n\\n    # Split resume text into paragraphs\\n    resume_lines = resume_text.split(\"\\n\")\\n\\n    # Add the resume content to the docx, while suggesting improvements\\n    for line in resume_lines:\\n        doc.add_paragraph(line)\\n\\n    # Insert a section for adding missing skills\\n    if missing_skills:\\n        doc.add_heading(\\'Suggested Improvements (Based on Job Description)\\', level=1)\\n        doc.add_paragraph(\\n            \"The following skills are suggested to be added based on the job description:\\n\" +\\n            \\', \\'.join(missing_skills) + \".\\nPlease consider adding them to your resume, especially in sections like \\'Skills\\' or \\'Experience\\'.\"\\n        )\\n\\n    # Add relevant skills (already in the resume)\\n    doc.add_heading(\\'Relevant Skills Already Present\\', level=1)\\n    doc.add_paragraph(\\', \\'.join(relevant_resume_skills))\\n\\n    # Return the tailored resume as a downloadable DOCX file\\n    output = BytesIO()\\n    doc.save(output)\\n    return output.getvalue()\\n\\n# Streamlit UI\\nst.title(\"GLA University ATS System\")\\nst.subheader(\"About\")\\nst.write(\"This sophisticated ATS project, developed with Gemini Pro and Streamlit, seamlessly incorporates advanced features including resume match percentage, keyword analysis to identify missing criteria, and the generation of comprehensive profile summaries, enhancing the efficiency and precision of the candidate evaluation process for discerning talent acquisition professionals.\")\\n\\nst.markdown(\"\"\"\\n  - [Streamlit](https://streamlit.io/)\\n  - [Gemini Pro](https://deepmind.google/technologies/gemini/#introduction)\\n  - [makersuit API Key](https://makersuite.google.com/)\\n\\n  \"\"\")\\n\\n# Sidebar for input\\nst.sidebar.header(\"Upload Your Job Description\")\\njob_desc_file = st.sidebar.file_uploader(\"Upload Job Description (PDF)\", type=\"pdf\")\\nop=st.sidebar.selectbox(\"Resume:\",[\"Choose an option\",\"Yes, I have\",\"No, I have to create.\"])\\n\\n#Prompts\\ninput_prompt1 = \"\"\"\\n You are an experienced Technical Human Resource Manager,your task is to review the provided resume against the job description.\\n  Please share your professional evaluation on whether the candidate\\'s profile aligns with the role.\\n Highlight the strengths and weaknesses of the applicant in relation to the specified job requirements.\\n\"\"\"\\n\\ninput_prompt3 = \"\"\"\\nYou are an skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality,\\nyour task is to evaluate the resume against the provided job description. give me the percentage of match if the resume matches\\nthe job description. The output should come as percentage.\\n\"\"\"\\n\\ninput_prompt4 = \"\"\"\\nYou are an skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality,\\nyour task is to evaluate the resume against the provided job description. give me the relevant skills if the resume matches\\nthe job description. The output should come as text containing all relevant skills required for given job description .\\n\"\"\"\\n\\ninput_prompt5 = \"\"\"\\nYou are an skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality,\\nyour task is to evaluate the resume against the provided job description. give me the non-relevant skills if the resume matches\\nthe job description. The output should come as text containing all non-relevant skills mentioned in resume that are not required for given job description .\\n\"\"\"\\n\\ninput_prompt6 = \"\"\"\\nYou are a skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality.\\nYour task is to evaluate the resume against the provided job description and return only the plagiarism score, expressed\\nas a percentage of similarity between the two documents.\\n\"\"\"\\n\\ninput_prompt7 = \"\"\"\\nYou are a skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality.\\nYour task is to evaluate the resume against the provided job description and return only the Relevant Projects, for the given job description.\\nThe output should come as text containing all relevant projects required for given job description.\\n\"\"\"\\n\\ninput_prompt8 = \"\"\"\\nYou are a skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality.\\nYour task is to evaluate the resume against the provided job description and return only the Recommended Skills required for Job Description, for the given resume.\\nThe output should come as text containing all recommended skills required for given job description.\\n\"\"\"\\n\\n\\nif op==\"Yes, I have\":\\n  pdf_file = st.sidebar.file_uploader(\"Upload Resume (PDF)\", type=\"pdf\")\\n\\n  opt = st.sidebar.selectbox(\"Available Options\", [\"Choose an option\",\"Percentage match\", \"Show Relevant Skills\", \"Non-relevant Skills\", \"Plagiarism Score\", \"Relevant Projects\", \"Recommended Skills\", \"Tell Me About the Resume\" , \"Tailor Resume\"])\\n\\n  # Option: Job Description Matching Score\\n  if opt == \"Percentage match\":\\n      if pdf_file is not None and job_desc_file is not None:\\n          pdf_content = input_pdf_setup(pdf_file)\\n          job_desc_text = input_pdf_setup(job_desc_file)\\n          response = get_gemini_response(input_prompt3, pdf_content, job_desc_text[0])\\n          st.subheader(\"Percentage Match\")\\n          st.write(response)\\n      else:\\n          st.write(\"Please upload both the resume and job description.\")\\n  # Option: Show Relevant Skills\\n  if opt == \"Show Relevant Skills\":\\n      if pdf_file is not None and job_desc_file is not None:\\n          pdf_content = input_pdf_setup(pdf_file)\\n          job_desc_text = input_pdf_setup(job_desc_file)  # Fix: initialize job_desc_text\\n          response = get_gemini_response(input_prompt4, pdf_content, job_desc_text[0])\\n          st.subheader(\"Relevant Skills\")\\n          st.write(response)\\n      else:\\n          st.write(\"Please upload both the resume and job description.\")\\n\\n  # Option: Non-relevant Skills\\n  if opt == \"Non-relevant Skills\":\\n      if pdf_file is not None and job_desc_file is not None:\\n          pdf_content = input_pdf_setup(pdf_file)\\n          job_desc_text = input_pdf_setup(job_desc_file)  # Fix: initialize job_desc_text\\n          response = get_gemini_response(input_prompt5, pdf_content, job_desc_text[0])\\n          st.subheader(\"Non-Relevant Skills\")\\n          st.write(response)\\n      else:\\n          st.write(\"Please upload both the resume and job description.\")\\n\\n  # Option: Plagiarism Score\\n  if opt == \"Plagiarism Score\":\\n      if pdf_file is not None and job_desc_file is not None:\\n          pdf_content = input_pdf_setup(pdf_file)\\n          job_desc_text = input_pdf_setup(job_desc_file)  # Fix: initialize job_desc_text\\n          response = get_gemini_response(input_prompt6, pdf_content, job_desc_text[0])\\n          st.subheader(\"Plagiarism Score\")\\n          st.write(response)\\n      else:\\n          st.write(\"Please upload both the resume and job description.\")\\n\\n  # Option: Relevant Projects\\n  if opt == \"Relevant Projects\":\\n      if pdf_file is not None and job_desc_file is not None:\\n          pdf_content = input_pdf_setup(pdf_file)\\n          job_desc_text = input_pdf_setup(job_desc_file)  # Fix: initialize job_desc_text\\n          response = get_gemini_response(input_prompt7, pdf_content, job_desc_text[0])\\n          st.subheader(\"Relevant Projects for the Job Description\")\\n          st.write(response)\\n      else:\\n          st.write(\"Please upload both the resume and job description.\")\\n\\n\\n  # Option: Recommended Skills\\n  if opt == \"Recommended Skills\":\\n      if pdf_file is not None and job_desc_file is not None:\\n          pdf_content = input_pdf_setup(pdf_file)\\n          job_desc_text = input_pdf_setup(job_desc_file)  # Fix: initialize job_desc_text\\n          response = get_gemini_response(input_prompt8, pdf_content, job_desc_text[0])\\n          st.subheader(\"Recommended Skills\")\\n          st.write(response)\\n      else:\\n          st.write(\"Please upload both the resume and job description.\")\\n\\n  # Option: Resume Summary\\n  if opt == \"Tell Me About the Resume\":\\n      if pdf_file is not None and job_desc_file is not None:\\n          pdf_content = input_pdf_setup(pdf_file)\\n          job_desc_text = input_pdf_setup(job_desc_file)  # Fix: initialize job_desc_text\\n          response = get_gemini_response(input_prompt1, pdf_content, job_desc_text[0])\\n          st.subheader(\"Resume Tells\")\\n          st.write(response)\\n      else:\\n          st.write(\"Please upload both the resume and job description.\")\\n\\n  # Option: Tailor Resume\\n  if opt == \"Tailor Resume\":\\n      if pdf_file is not None and job_desc_file is not None:\\n          pdf_content = input_pdf_setup(pdf_file)\\n          job_desc_text = input_pdf_setup(job_desc_file)\\n          tailored_resume = tailor_resume(pdf_content[0], job_desc_text[0])\\n\\n          st.download_button(\\n              label=\"Download Tailored Resume (DOCX)\",\\n              data=tailored_resume,\\n              file_name=\"tailored_resume.docx\",\\n              mime=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"\\n          )\\n\\n          st.header(\"Tailored Resume Suggestions\")\\n          st.write(\"Your resume has been tailored with suggestions on adding missing skills and highlighting relevant ones.\")\\n      else:\\n          st.write(\"Please upload both the resume and job description.\")\\n\\nif op==\"No, I have to create.\":\\n  generate_resume()\\n'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import PyPDF2\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from docx import Document\n",
        "import difflib  # For calculating similarity in plagiarism check\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "import base64\n",
        "import os\n",
        "from PIL import Image\n",
        "import pdf2image\n",
        "import google.generativeai as genai\n",
        "from io import BytesIO\n",
        "from fpdf import FPDF\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "# Configure Google Generative AI\n",
        "genai.configure(api_key=(\"AIzaSyAHrZuX0mzeKQUTtUNX1zv3dNO-m56T_nU\"))\n",
        "\n",
        "\n",
        "def get_gemini_response(input, pdf_content, prompt):\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "    response = model.generate_content([input, pdf_content[0], prompt])\n",
        "    return response.text\n",
        "\n",
        "def get_gemini_response1(input_prompt):\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "    response = model.generate_content(input_prompt)\n",
        "    return response.text\n",
        "\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    reader = PyPDF2.PdfReader(pdf_file)\n",
        "    text = ''\n",
        "    for page_num in range(len(reader.pages)):\n",
        "        page = reader.pages[page_num]\n",
        "        text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "\n",
        "def input_pdf_setup(pdf_file):\n",
        "    return [extract_text_from_pdf(pdf_file)]\n",
        "\n",
        "def extract_skills(text):\n",
        "    skill_set = {'python', 'java', 'data analysis', 'project management', 'machine learning', 'communication', 'sql'}\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    cleaned_tokens = [word for word in tokens if word.isalpha() and word not in stopwords.words('english')]\n",
        "    relevant_skills = skill_set.intersection(cleaned_tokens)\n",
        "    return relevant_skills\n",
        "\n",
        "def generate_pdf(content):\n",
        "    # Function to generate a PDF from the given resume content\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "\n",
        "    # Split content into lines and add each line to the PDF\n",
        "    for line in content.split(\"\\n\"):\n",
        "        pdf.cell(200, 10, txt=line, ln=True)\n",
        "\n",
        "    # Save the PDF to a BytesIO object\n",
        "    pdf_output = BytesIO()\n",
        "    pdf.output(pdf_output)\n",
        "    pdf_output.seek(0)\n",
        "\n",
        "    return pdf_output\n",
        "\n",
        "def generate_pdf(content):\n",
        "    # Function to generate a PDF from the given resume content\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "\n",
        "    # Replace unsupported Unicode characters\n",
        "    content = content.replace(\"\\u2013\", \"-\")  # Replace en-dash with a hyphen\n",
        "    content = content.replace(\"\\u2014\", \"--\")  # Replace em-dash with double hyphen\n",
        "    content = content.replace(\"\\u2022\", \"*\")  # Replace bullet points with asterisks\n",
        "\n",
        "    # Split content into lines and add each line to the PDF\n",
        "    for line in content.split(\"\\n\"):\n",
        "        try:\n",
        "            pdf.cell(200, 10, txt=line.encode('latin-1', 'replace').decode('latin-1'), ln=True)\n",
        "        except UnicodeEncodeError as e:\n",
        "            st.error(f\"Error encoding line: {line} - {e}\")\n",
        "\n",
        "    # Save the PDF to a BytesIO object\n",
        "    pdf_output = BytesIO()\n",
        "    pdf.output(pdf_output)\n",
        "    pdf_output.seek(0)\n",
        "\n",
        "    return pdf_output\n",
        "\n",
        "def generate_resume():\n",
        "    st.header(\"Create Your Resume\")\n",
        "\n",
        "    # Taking inputs from the user\n",
        "    name = st.text_input(\"Enter Name\")\n",
        "    email = st.text_input(\"Enter Email\")\n",
        "    phone = st.text_input(\"Enter Phone Number\")\n",
        "    skills = st.text_area(\"Enter Skills\")\n",
        "    education = st.text_area(\"Enter Education\")\n",
        "    work_experience = st.text_area(\"Enter Work Experience\")\n",
        "    projects = st.text_area(\"Enter Projects\")\n",
        "    achievements = st.text_area(\"Enter Achievements\")\n",
        "    certifications = st.text_area(\"Enter Certifications\")\n",
        "    hobbies = st.text_area(\"Enter Hobbies\")\n",
        "\n",
        "    # Once all inputs are received\n",
        "    if st.button(\"Generate Resume\"):\n",
        "        # Prepare the input prompt for AI generation\n",
        "        input_prompt9 = f\"\"\"\n",
        "        You are a skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality.\n",
        "        Your task is to create the resume for the provided job description and return the resume that was created by using the user inputs:\n",
        "        Name: {name}\n",
        "        Email: {email}\n",
        "        Phone Number: {phone}\n",
        "\n",
        "        Skills: {skills}\n",
        "\n",
        "        Education: {education}\n",
        "\n",
        "        Work Experience: {work_experience}\n",
        "\n",
        "        Projects: {projects}\n",
        "\n",
        "        Achievements: {achievements}\n",
        "\n",
        "        Certifications: {certifications}\n",
        "\n",
        "        Hobbies: {hobbies}\n",
        "        The output should come as a PDF file containing the generated resume.\n",
        "        \"\"\"\n",
        "\n",
        "        # Get the response from the AI model\n",
        "        response = get_gemini_response1(input_prompt9)\n",
        "\n",
        "        # Display the generated resume to the user\n",
        "        st.subheader(\"Generated Resume\")\n",
        "        st.write(response)\n",
        "\n",
        "        # Generate a PDF from the response\n",
        "        pdf = generate_pdf(response)\n",
        "\n",
        "        # Provide a download button for the generated PDF\n",
        "        st.download_button(\n",
        "            label=\"Download Resume as PDF\",\n",
        "            data=pdf,\n",
        "            file_name=f\"{name}_resume.pdf\",\n",
        "            mime=\"application/pdf\"\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def tailor_resume(resume_text, job_desc_text):\n",
        "    # Extract skills from the job description\n",
        "    jd_skills = extract_skills(job_desc_text)\n",
        "\n",
        "    # Tokenize and clean the resume text\n",
        "    resume_tokens = word_tokenize(resume_text.lower())\n",
        "    resume_cleaned_tokens = [word for word in resume_tokens if word.isalpha() and word not in stopwords.words('english')]\n",
        "\n",
        "    # Identify relevant and missing skills\n",
        "    relevant_resume_skills = set(resume_cleaned_tokens).intersection(jd_skills)\n",
        "    missing_skills = jd_skills - relevant_resume_skills\n",
        "\n",
        "    # Load resume into a docx template for editing\n",
        "    doc = Document()\n",
        "    doc.add_heading('Tailored Resume', 0)\n",
        "\n",
        "    # Split resume text into paragraphs\n",
        "    resume_lines = resume_text.split(\"\\n\")\n",
        "\n",
        "    # Add the resume content to the docx, while suggesting improvements\n",
        "    for line in resume_lines:\n",
        "        doc.add_paragraph(line)\n",
        "\n",
        "    # Insert a section for adding missing skills\n",
        "    if missing_skills:\n",
        "        doc.add_heading('Suggested Improvements (Based on Job Description)', level=1)\n",
        "        doc.add_paragraph(\n",
        "            \"The following skills are suggested to be added based on the job description:\\n\" +\n",
        "            ', '.join(missing_skills) + \".\\nPlease consider adding them to your resume, especially in sections like 'Skills' or 'Experience'.\"\n",
        "        )\n",
        "\n",
        "    # Add relevant skills (already in the resume)\n",
        "    doc.add_heading('Relevant Skills Already Present', level=1)\n",
        "    doc.add_paragraph(', '.join(relevant_resume_skills))\n",
        "\n",
        "    # Return the tailored resume as a downloadable DOCX file\n",
        "    output = BytesIO()\n",
        "    doc.save(output)\n",
        "    return output.getvalue()\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"GLA University ATS System\")\n",
        "st.subheader(\"About\")\n",
        "st.write(\"This sophisticated ATS project, developed with Gemini Pro and Streamlit, seamlessly incorporates advanced features including resume match percentage, keyword analysis to identify missing criteria, and the generation of comprehensive profile summaries, enhancing the efficiency and precision of the candidate evaluation process for discerning talent acquisition professionals.\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "  - [Streamlit](https://streamlit.io/)\n",
        "  - [Gemini Pro](https://deepmind.google/technologies/gemini/#introduction)\n",
        "  - [makersuit API Key](https://makersuite.google.com/)\n",
        "\n",
        "  \"\"\")\n",
        "\n",
        "# Sidebar for input\n",
        "st.sidebar.header(\"Upload Your Job Description\")\n",
        "job_desc_file = st.sidebar.file_uploader(\"Upload Job Description (PDF)\", type=\"pdf\")\n",
        "op=st.sidebar.selectbox(\"Resume:\",[\"Choose an option\",\"Yes, I have\",\"No, I have to create.\"])\n",
        "\n",
        "#Prompts\n",
        "input_prompt1 = \"\"\"\n",
        " You are an experienced Technical Human Resource Manager,your task is to review the provided resume against the job description.\n",
        "  Please share your professional evaluation on whether the candidate's profile aligns with the role.\n",
        " Highlight the strengths and weaknesses of the applicant in relation to the specified job requirements.\n",
        "\"\"\"\n",
        "\n",
        "input_prompt3 = \"\"\"\n",
        "You are an skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality,\n",
        "your task is to evaluate the resume against the provided job description. give me the percentage of match if the resume matches\n",
        "the job description. The output should come as percentage.\n",
        "\"\"\"\n",
        "\n",
        "input_prompt4 = \"\"\"\n",
        "You are an skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality,\n",
        "your task is to evaluate the resume against the provided job description. give me the relevant skills if the resume matches\n",
        "the job description. The output should come as text containing all relevant skills required for given job description .\n",
        "\"\"\"\n",
        "\n",
        "input_prompt5 = \"\"\"\n",
        "You are an skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality,\n",
        "your task is to evaluate the resume against the provided job description. give me the non-relevant skills if the resume matches\n",
        "the job description. The output should come as text containing all non-relevant skills mentioned in resume that are not required for given job description .\n",
        "\"\"\"\n",
        "\n",
        "input_prompt6 = \"\"\"\n",
        "You are a skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality.\n",
        "Your task is to evaluate the resume against the provided job description and return only the plagiarism score, expressed\n",
        "as a percentage of similarity between the two documents.\n",
        "\"\"\"\n",
        "\n",
        "input_prompt7 = \"\"\"\n",
        "You are a skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality.\n",
        "Your task is to evaluate the resume against the provided job description and return only the Relevant Projects, for the given job description.\n",
        "The output should come as text containing all relevant projects required for given job description.\n",
        "\"\"\"\n",
        "\n",
        "input_prompt8 = \"\"\"\n",
        "You are a skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality.\n",
        "Your task is to evaluate the resume against the provided job description and return only the Recommended Skills required for Job Description, for the given resume.\n",
        "The output should come as text containing all recommended skills required for given job description.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "if op==\"Yes, I have\":\n",
        "  pdf_file = st.sidebar.file_uploader(\"Upload Resume (PDF)\", type=\"pdf\")\n",
        "\n",
        "  opt = st.sidebar.selectbox(\"Available Options\", [\"Choose an option\",\"Percentage match\", \"Show Relevant Skills\", \"Non-relevant Skills\", \"Plagiarism Score\", \"Relevant Projects\", \"Recommended Skills\", \"Tell Me About the Resume\" , \"Tailor Resume\"])\n",
        "\n",
        "  # Option: Job Description Matching Score\n",
        "  if opt == \"Percentage match\":\n",
        "      if pdf_file is not None and job_desc_file is not None:\n",
        "          pdf_content = input_pdf_setup(pdf_file)\n",
        "          job_desc_text = input_pdf_setup(job_desc_file)\n",
        "          response = get_gemini_response(input_prompt3, pdf_content, job_desc_text[0])\n",
        "          st.subheader(\"Percentage Match\")\n",
        "          st.write(response)\n",
        "      else:\n",
        "          st.write(\"Please upload both the resume and job description.\")\n",
        "  # Option: Show Relevant Skills\n",
        "  if opt == \"Show Relevant Skills\":\n",
        "      if pdf_file is not None and job_desc_file is not None:\n",
        "          pdf_content = input_pdf_setup(pdf_file)\n",
        "          job_desc_text = input_pdf_setup(job_desc_file)  # Fix: initialize job_desc_text\n",
        "          response = get_gemini_response(input_prompt4, pdf_content, job_desc_text[0])\n",
        "          st.subheader(\"Relevant Skills\")\n",
        "          st.write(response)\n",
        "      else:\n",
        "          st.write(\"Please upload both the resume and job description.\")\n",
        "\n",
        "  # Option: Non-relevant Skills\n",
        "  if opt == \"Non-relevant Skills\":\n",
        "      if pdf_file is not None and job_desc_file is not None:\n",
        "          pdf_content = input_pdf_setup(pdf_file)\n",
        "          job_desc_text = input_pdf_setup(job_desc_file)  # Fix: initialize job_desc_text\n",
        "          response = get_gemini_response(input_prompt5, pdf_content, job_desc_text[0])\n",
        "          st.subheader(\"Non-Relevant Skills\")\n",
        "          st.write(response)\n",
        "      else:\n",
        "          st.write(\"Please upload both the resume and job description.\")\n",
        "\n",
        "  # Option: Plagiarism Score\n",
        "  if opt == \"Plagiarism Score\":\n",
        "      if pdf_file is not None and job_desc_file is not None:\n",
        "          pdf_content = input_pdf_setup(pdf_file)\n",
        "          job_desc_text = input_pdf_setup(job_desc_file)  # Fix: initialize job_desc_text\n",
        "          response = get_gemini_response(input_prompt6, pdf_content, job_desc_text[0])\n",
        "          st.subheader(\"Plagiarism Score\")\n",
        "          st.write(response)\n",
        "      else:\n",
        "          st.write(\"Please upload both the resume and job description.\")\n",
        "\n",
        "  # Option: Relevant Projects\n",
        "  if opt == \"Relevant Projects\":\n",
        "      if pdf_file is not None and job_desc_file is not None:\n",
        "          pdf_content = input_pdf_setup(pdf_file)\n",
        "          job_desc_text = input_pdf_setup(job_desc_file)  # Fix: initialize job_desc_text\n",
        "          response = get_gemini_response(input_prompt7, pdf_content, job_desc_text[0])\n",
        "          st.subheader(\"Relevant Projects for the Job Description\")\n",
        "          st.write(response)\n",
        "      else:\n",
        "          st.write(\"Please upload both the resume and job description.\")\n",
        "\n",
        "\n",
        "  # Option: Recommended Skills\n",
        "  if opt == \"Recommended Skills\":\n",
        "      if pdf_file is not None and job_desc_file is not None:\n",
        "          pdf_content = input_pdf_setup(pdf_file)\n",
        "          job_desc_text = input_pdf_setup(job_desc_file)  # Fix: initialize job_desc_text\n",
        "          response = get_gemini_response(input_prompt8, pdf_content, job_desc_text[0])\n",
        "          st.subheader(\"Recommended Skills\")\n",
        "          st.write(response)\n",
        "      else:\n",
        "          st.write(\"Please upload both the resume and job description.\")\n",
        "\n",
        "  # Option: Resume Summary\n",
        "  if opt == \"Tell Me About the Resume\":\n",
        "      if pdf_file is not None and job_desc_file is not None:\n",
        "          pdf_content = input_pdf_setup(pdf_file)\n",
        "          job_desc_text = input_pdf_setup(job_desc_file)  # Fix: initialize job_desc_text\n",
        "          response = get_gemini_response(input_prompt1, pdf_content, job_desc_text[0])\n",
        "          st.subheader(\"Resume Tells\")\n",
        "          st.write(response)\n",
        "      else:\n",
        "          st.write(\"Please upload both the resume and job description.\")\n",
        "\n",
        "  # Option: Tailor Resume\n",
        "  if opt == \"Tailor Resume\":\n",
        "      if pdf_file is not None and job_desc_file is not None:\n",
        "          pdf_content = input_pdf_setup(pdf_file)\n",
        "          job_desc_text = input_pdf_setup(job_desc_file)\n",
        "          tailored_resume = tailor_resume(pdf_content[0], job_desc_text[0])\n",
        "\n",
        "          st.download_button(\n",
        "              label=\"Download Tailored Resume (DOCX)\",\n",
        "              data=tailored_resume,\n",
        "              file_name=\"tailored_resume.docx\",\n",
        "              mime=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"\n",
        "          )\n",
        "\n",
        "          st.header(\"Tailored Resume Suggestions\")\n",
        "          st.write(\"Your resume has been tailored with suggestions on adding missing skills and highlighting relevant ones.\")\n",
        "      else:\n",
        "          st.write(\"Please upload both the resume and job description.\")\n",
        "\n",
        "if op==\"No, I have to create.\":\n",
        "  generate_resume()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgNXUQYB31DI",
        "outputId": "cd37ac48-fa6c-4ff4-fbf2-9c4b3b069b92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import PyPDF2\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from docx import Document\n",
        "import difflib  # For calculating similarity in plagiarism check\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "import base64\n",
        "import os\n",
        "from PIL import Image\n",
        "import pdf2image\n",
        "import google.generativeai as genai\n",
        "from io import BytesIO\n",
        "from fpdf import FPDF\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Set Streamlit page config at the top\n",
        "st.set_page_config(page_title=\"GLA ATS System\", page_icon=\":guardsman:\")\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Configure Google Generative AI\n",
        "genai.configure(api_key=(\"AIzaSyBPDNB9oDlVpJlTdEkEnc7vWv_CsAZiVQ0\"))\n",
        "\n",
        "def get_gemini_response(input, pdf_content, prompt):\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "    response = model.generate_content([input, pdf_content[0], prompt])\n",
        "    return response.text\n",
        "\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    reader = PyPDF2.PdfReader(pdf_file)\n",
        "    text = ''\n",
        "    for page_num in range(len(reader.pages)):\n",
        "        page = reader.pages[page_num]\n",
        "        text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def input_pdf_setup(pdf_file):\n",
        "    return [extract_text_from_pdf(pdf_file)]\n",
        "\n",
        "# Define the PDF class\n",
        "class PDF(FPDF):\n",
        "    def add_section(self, title, content):\n",
        "        # Add section title\n",
        "        self.set_font('Arial', 'B', 14)\n",
        "        self.cell(200, 10, title, ln=True)\n",
        "        self.set_font('Arial', '', 12)\n",
        "        self.multi_cell(0, 10, content)\n",
        "        self.ln(5)  # Add some space after each section\n",
        "\n",
        "def generate_pdf(name, email, phone, skills, education, work_experience, projects, achievements, certifications, hobbies):\n",
        "    pdf = PDF()\n",
        "    pdf.add_page()\n",
        "\n",
        "    # Header with name, email, and phone\n",
        "    pdf.set_font('Arial', 'B', 16)\n",
        "    pdf.set_text_color(0, 51, 102)  # Blue color for name\n",
        "    pdf.cell(200, 10, name, ln=True, align='C')\n",
        "\n",
        "    pdf.set_font('Arial', 'I', 12)\n",
        "    pdf.set_text_color(0, 0, 0)  # Black for email and phone\n",
        "    pdf.cell(200, 10, f'{email} | {phone}', ln=True, align='C')\n",
        "\n",
        "    pdf.ln(10)  # Space after header\n",
        "\n",
        "    # Adding sections to the PDF\n",
        "    sections = {\n",
        "        \"Skills\": skills,\n",
        "        \"Education\": education,\n",
        "        \"Work Experience\": work_experience,\n",
        "        \"Projects\": projects,\n",
        "        \"Achievements\": achievements,\n",
        "        \"Certifications\": certifications,\n",
        "        \"Hobbies\": hobbies\n",
        "    }\n",
        "\n",
        "    for title, content in sections.items():\n",
        "        if content:\n",
        "            pdf.add_section(title, content)\n",
        "\n",
        "    # Save to BytesIO\n",
        "    pdf_output = BytesIO()\n",
        "    pdf.output(pdf_output, 'S')\n",
        "    pdf_output.seek(0)  # Move to the beginning of the BytesIO stream\n",
        "\n",
        "    return pdf_output\n",
        "\n",
        "def generate_resume():\n",
        "   import streamlit as st\n",
        "\n",
        "# Function to generate PDF\n",
        "def generate_pdf(name, email, phone, skills, education, work_experience, projects, achievements, certifications, hobbies):\n",
        "    from io import BytesIO\n",
        "    from reportlab.lib.pagesizes import letter\n",
        "    from reportlab.pdfgen import canvas\n",
        "\n",
        "    buffer = BytesIO()\n",
        "    c = canvas.Canvas(buffer, pagesize=letter)\n",
        "    text = c.beginText(50, 750)\n",
        "\n",
        "    # Add content to the PDF\n",
        "    text.setFont(\"Helvetica\", 12)\n",
        "    text.textLine(f\"Name: {name}\")\n",
        "    text.textLine(f\"Email: {email}\")\n",
        "    text.textLine(f\"Phone: {phone}\")\n",
        "    text.textLine(\"Skills:\")\n",
        "    text.textLines(skills)\n",
        "    text.textLine(\"Education:\")\n",
        "    text.textLines(education)\n",
        "    text.textLine(\"Work Experience:\")\n",
        "    text.textLines(work_experience)\n",
        "    text.textLine(\"Projects:\")\n",
        "    text.textLines(projects)\n",
        "    text.textLine(\"Achievements:\")\n",
        "    text.textLines(achievements)\n",
        "    text.textLine(\"Certifications:\")\n",
        "    text.textLines(certifications)\n",
        "    text.textLine(\"Hobbies:\")\n",
        "    text.textLines(hobbies)\n",
        "\n",
        "    c.drawText(text)\n",
        "    c.save()\n",
        "\n",
        "    buffer.seek(0)\n",
        "    return buffer\n",
        "\n",
        "# Streamlit app\n",
        "st.title(\"Resume Generator\")\n",
        "\n",
        "# User inputs\n",
        "name = st.text_input(\"Name\")\n",
        "email = st.text_input(\"Email\")\n",
        "phone = st.text_input(\"Phone Number\")\n",
        "skills = st.text_area(\"Skills\")\n",
        "education = st.text_area(\"Education\")\n",
        "work_experience = st.text_area(\"Work Experience\")\n",
        "projects = st.text_area(\"Projects\")\n",
        "achievements = st.text_area(\"Achievements\")\n",
        "certifications = st.text_area(\"Certifications\")\n",
        "hobbies = st.text_area(\"Hobbies\")\n",
        "\n",
        "# Generate Resume\n",
        "if st.button(\"Generate Resume\"):\n",
        "    # Check if all fields are filled\n",
        "    if not all([name, email, phone, skills, education, work_experience, projects, achievements, certifications, hobbies]):\n",
        "        st.warning(\"Please fill in all fields before generating the resume.\")\n",
        "    else:\n",
        "        # Generate the PDF\n",
        "        pdf = generate_pdf(\n",
        "            name,\n",
        "            email,\n",
        "            phone,\n",
        "            skills,\n",
        "            education,\n",
        "            work_experience,\n",
        "            projects,\n",
        "            achievements,\n",
        "            certifications,\n",
        "            hobbies,\n",
        "        )\n",
        "\n",
        "        # Provide download link\n",
        "        st.download_button(\n",
        "            label=\"Download PDF\",\n",
        "            data=pdf,\n",
        "            file_name=\"resume.pdf\",\n",
        "            mime=\"application/pdf\"\n",
        "        )\n",
        "\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"**GLA University ATS System**\")\n",
        "st.subheader(\"About\")\n",
        "st.write(\"This sophisticated ATS project, developed with Gemini Pro and Streamlit, seamlessly incorporates advanced features including resume match percentage, keyword analysis to identify missing criteria, and the generation of comprehensive profile summaries, enhancing the efficiency and precision of the candidate evaluation process for discerning talent acquisition professionals.\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "  - [Streamlit](https://streamlit.io/)\n",
        "  - [Gemini Pro](https://deepmind.google/technologies/gemini/#introduction)\n",
        "  - [makersuit API Key](https://makersuite.google.com/)\n",
        "\"\"\")\n",
        "\n",
        "# Sidebar for input\n",
        "st.sidebar.header(\"Upload Your Job Description\")\n",
        "job_desc_file = st.sidebar.file_uploader(\"Upload Job Description (PDF)\", type=\"pdf\")\n",
        "\n",
        "\n",
        "#Prompts\n",
        "input_prompt1 = \"\"\"\n",
        " You are an experienced Technical Human Resource Manager,your task is to review the provided resume against the job description.\n",
        "  Please share your professional evaluation on whether the candidate's profile aligns with the role.\n",
        " Highlight the strengths and weaknesses of the applicant in relation to the specified job requirements.\n",
        "\"\"\"\n",
        "\n",
        "input_prompt3 = \"\"\"\n",
        "You are a skilled ATS (Applicant Tracking System) scanner with a deep understanding of ATS functionality.\n",
        "Your task is to evaluate the resume_pdf_content against the provided pdf_content and provide a match percentage.\n",
        "The output should be a numerical percentage value only, without any additional text or symbols (e.g., 75).\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "input_prompt4 = \"\"\"\n",
        "You are an skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality,\n",
        "your task is to evaluate the resume against the provided job description. give me the relevant skills if the resume matches\n",
        "the job description. The output should come as text containing all relevant skills required for given job description .\n",
        "\"\"\"\n",
        "\n",
        "input_prompt5 = \"\"\"\n",
        "You are an skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality,\n",
        "your task is to evaluate the resume against the provided job description. give me the non-relevant skills if the resume matches\n",
        "the job description. The output should come as text containing all non-relevant skills mentioned in resume that are not required for given job description .\n",
        "\"\"\"\n",
        "\n",
        "input_prompt6 = \"\"\"\n",
        "You are a skilled ATS (Applicant Tracking System) scanner with a deep understanding of ATS functionality.\n",
        "Your task is to evaluate the resume_text against the provided job description and provide a plagiarism percentage.\n",
        "The output should be a numerical percentage value only, without any additional text or symbols (e.g., 75).\n",
        "\"\"\"\n",
        "\n",
        "input_prompt7 = \"\"\"\n",
        "You are a skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality.\n",
        "Your task is to evaluate the resume against the provided job description and return only the Relevant Projects, for the given job description.\n",
        "The output should come as text containing all relevant projects required for given job description.\n",
        "\"\"\"\n",
        "\n",
        "input_prompt8 = \"\"\"\n",
        "You are a skilled ATS (Applicant Tracking System) scanner with a deep understanding of data science and ATS functionality.\n",
        "Your task is to evaluate the resume against the provided job description and return only the Recommended Skills required that are not available in resume but given in job description.\n",
        "The output should come as text containing all recommended skills required for given job description.\n",
        "\"\"\"\n",
        "\n",
        "# If a job description is uploaded\n",
        "if job_desc_file is not None:\n",
        "    op = st.sidebar.selectbox(\"Resume:\", [\"Choose an option\", \"Yes, I have\", \"No, I have to create.\"])\n",
        "    pdf_content = input_pdf_setup(job_desc_file)\n",
        "    job_desc_text = pdf_content[0]\n",
        "\n",
        "    # Call the API with the prompts\n",
        "    if op == \"Yes, I have\":\n",
        "        st.subheader(\"Your Resume\")\n",
        "        resume_file = st.file_uploader(\"Upload Your Resume (PDF)\", type=\"pdf\")\n",
        "\n",
        "        if resume_file is not None:\n",
        "            opt = st.sidebar.selectbox(\"Available Options\", [\"Choose an option\",\"Percentage match\", \"Show Relevant Skills\", \"Non-relevant Skills\", \"Plagiarism Score\", \"Relevant Projects\", \"Recommended Skills\", \"Tell Me About the Resume\" , \"Tailor Resume\"])\n",
        "            resume_pdf_content = input_pdf_setup(resume_file)\n",
        "            resume_text = resume_pdf_content[0]\n",
        "\n",
        "            # Get match percentage\n",
        "            if opt == \"Percentage match\":\n",
        "              response = get_gemini_response(input_prompt3, resume_pdf_content, job_desc_text[0])\n",
        "              # Display the percentage as a progress bar\n",
        "              st.subheader(\"Percentage Match\")\n",
        "              st.progress(int(response))\n",
        "              st.write(f\"Match: {response}%\")\n",
        "\n",
        "            # Get relevant skills\n",
        "            if opt == \"Show Relevant Skills\":\n",
        "              relevant_skills = get_gemini_response(resume_text, pdf_content, input_prompt4)\n",
        "              st.write(\"Relevant Skills:\")\n",
        "              st.write(relevant_skills)\n",
        "\n",
        "            # Get non-relevant skills\n",
        "            if opt == \"Non-relevant Skills\":\n",
        "              non_relevant_skills = get_gemini_response(resume_text, pdf_content, input_prompt5)\n",
        "              st.write(\"Non-Relevant Skills:\")\n",
        "              st.write(non_relevant_skills)\n",
        "\n",
        "            # Get plagiarism percentage\n",
        "            if opt == \"Plagiarism Score\":\n",
        "              response = get_gemini_response(input_prompt6, resume_pdf_content, job_desc_text[0])\n",
        "              st.subheader(\"Plagiarism Score\")\n",
        "              # Display the percentage as a progress bar\n",
        "              st.progress(int(response))\n",
        "              st.write(f\"Match: {response}%\")\n",
        "\n",
        "            # Get relevant projects\n",
        "            if opt == \"Relevant Projects\":\n",
        "              relevant_projects = get_gemini_response(resume_text, pdf_content, input_prompt7)\n",
        "              st.write(\"Relevant Projects:\")\n",
        "              st.write(relevant_projects)\n",
        "\n",
        "            # Get recommended skills\n",
        "            if opt == \"Recommended Skills\":\n",
        "              recommended_skills = get_gemini_response(resume_text, pdf_content, input_prompt8)\n",
        "              st.write(\"Recommended Skills:\")\n",
        "              st.write(recommended_skills)\n",
        "\n",
        "            if opt == \"Tell Me About the Resume\":\n",
        "              response = get_gemini_response(input_prompt1, resume_pdf_content, job_desc_text[0])\n",
        "              st.subheader(\"Resume Tells\")\n",
        "              st.write(response)\n",
        "\n",
        "\n",
        "    if op == \"No, I have to create.\":\n",
        "        generate_resume()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIkD3W6nbMYq",
        "outputId": "24d60075-38b8-4fc7-c348-3477e4c50500"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'npm' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "& was unexpected at this time.\n"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel\n",
        "\n",
        "!streamlit run /content/app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XSaYQPsbM0V",
        "outputId": "0b60ee8d-f789-4fec-c71a-27a4c4d1f3cd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFA4xFZAbPbv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
